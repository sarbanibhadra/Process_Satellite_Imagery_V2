{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b424372-bb62-4ec0-900a-fa9486570951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "lenght of table id 13\n",
      "Processing table ID: LARSE/GEDI/GEDI04_A_002/GEDI04_A_2023067000412_O23978_02_T02431_02_003_01_V002\n",
      "Processing table ID: LARSE/GEDI/GEDI04_A_002/GEDI04_A_2023067000412_O23978_01_T02431_02_003_01_V002\n",
      "Processing table ID: LARSE/GEDI/GEDI04_A_002/GEDI04_A_2023075201011_O24115_02_T08796_02_003_01_V002\n",
      "Processing table ID: LARSE/GEDI/GEDI04_A_002/GEDI04_A_2023075201011_O24115_01_T08796_02_003_01_V002\n",
      "Processing table ID: LARSE/GEDI/GEDI04_A_002/GEDI04_A_2023074205634_O24100_02_T03854_02_003_01_V002\n",
      "Processing table ID: LARSE/GEDI/GEDI04_A_002/GEDI04_A_2023074205634_O24100_01_T03854_02_003_01_V002\n",
      "Processing table ID: LARSE/GEDI/GEDI04_A_002/GEDI04_A_2023074083331_O24092_04_T09997_02_003_01_V002\n",
      "Processing table ID: LARSE/GEDI/GEDI04_A_002/GEDI04_A_2023074083331_O24092_03_T09997_02_003_01_V002\n",
      "Processing table ID: LARSE/GEDI/GEDI04_A_002/GEDI04_A_2023073214320_O24085_01_T07450_02_003_01_V002\n",
      "Processing table ID: LARSE/GEDI/GEDI04_A_002/GEDI04_A_2023073092016_O24077_04_T06325_02_003_01_V002\n",
      "Processing table ID: LARSE/GEDI/GEDI04_A_002/GEDI04_A_2023073092016_O24077_03_T06325_02_003_01_V002\n",
      "Processing table ID: LARSE/GEDI/GEDI04_A_002/GEDI04_A_2023072223004_O24070_02_T09470_02_003_01_V002\n",
      "Processing table ID: LARSE/GEDI/GEDI04_A_002/GEDI04_A_2023067122714_O23986_04_T06249_02_003_01_V002\n",
      "Training the model\n",
      "Error Matrix: <class 'ee.confusionmatrix.ConfusionMatrix'>\n",
      "<class 'ee.imagecollection.ImageCollection'>\n",
      "Finish1\n",
      "<class 'ee.imagecollection.ImageCollection'>\n",
      "Finish2\n"
     ]
    },
    {
     "ename": "EEException",
     "evalue": "Computation timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/agb-venv/lib/python3.11/site-packages/ee/data.py:406\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/agb-venv/lib/python3.11/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/agb-venv/lib/python3.11/site-packages/googleapiclient/http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1/projects/test-project-agb/maps?fields=name&alt=json returned \"Computation timed out.\". Details: \"Computation timed out.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 366\u001b[0m\n\u001b[1;32m    321\u001b[0m task \u001b[38;5;241m=\u001b[39m ee\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mExport\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mtoCloudStorage(\n\u001b[1;32m    322\u001b[0m     image\u001b[38;5;241m=\u001b[39magb_prediction_image,\n\u001b[1;32m    323\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magb_prediction_image\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    328\u001b[0m     fileFormat\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGEO_TIFF\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Export format\u001b[39;00m\n\u001b[1;32m    329\u001b[0m )\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# # Configure the export task\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# task = ee.batch.Export.table.toCloudStorage(\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m#     collection=feature_collection,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# # Start monitoring the task\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# check_task_status(task)\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m \u001b[43mMap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentinel1_final_filled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m  \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentinel1_final_filled\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    369\u001b[0m \u001b[43m)\u001b[49m;\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# Map.addLayer(composite, \u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m#   {'min': -25, 'max': 5},  \u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m#   'composite'\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# );\u001b[39;00m\n\u001b[1;32m    376\u001b[0m Map\u001b[38;5;241m.\u001b[39maddLayer(sentinel2, \n\u001b[1;32m    377\u001b[0m   {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m25\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m}, \n\u001b[1;32m    378\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    379\u001b[0m );\n",
      "File \u001b[0;32m~/agb-venv/lib/python3.11/site-packages/geemap/geemap.py:1448\u001b[0m, in \u001b[0;36mMap.add_ee_layer\u001b[0;34m(self, ee_object, vis_params, name, shown, opacity)\u001b[0m\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(vis_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpalette\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m   1444\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1445\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe palette must be a list of colors or a string or a Box object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1446\u001b[0m         )\n\u001b[0;32m-> 1448\u001b[0m map_id_dict \u001b[38;5;241m=\u001b[39m \u001b[43mee\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetMapId\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvis_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m tile_layer \u001b[38;5;241m=\u001b[39m ipyleaflet\u001b[38;5;241m.\u001b[39mTileLayer(\n\u001b[1;32m   1450\u001b[0m     url\u001b[38;5;241m=\u001b[39mmap_id_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtile_fetcher\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39murl_format,\n\u001b[1;32m   1451\u001b[0m     attribution\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoogle Earth Engine\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     max_zoom\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m,\n\u001b[1;32m   1456\u001b[0m )\n\u001b[1;32m   1458\u001b[0m layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_layer(name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/agb-venv/lib/python3.11/site-packages/ee/image.py:156\u001b[0m, in \u001b[0;36mImage.getMapId\u001b[0;34m(self, vis_params)\u001b[0m\n\u001b[1;32m    154\u001b[0m vis_image, request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_visualization(vis_params)\n\u001b[1;32m    155\u001b[0m request[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m vis_image\n\u001b[0;32m--> 156\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetMapId\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/agb-venv/lib/python3.11/site-packages/ee/data.py:748\u001b[0m, in \u001b[0;36mgetMapId\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    743\u001b[0m queryParams \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfields\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m: request,\n\u001b[1;32m    746\u001b[0m }\n\u001b[1;32m    747\u001b[0m _maybe_populate_workload_tag(queryParams)\n\u001b[0;32m--> 748\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_cloud_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mqueryParams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    753\u001b[0m map_name \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    754\u001b[0m url_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/tiles/\u001b[39m\u001b[38;5;132;01m{z}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{x}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{y}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    755\u001b[0m     _tile_base_url, _cloud_api_utils\u001b[38;5;241m.\u001b[39mVERSION, map_name)\n",
      "File \u001b[0;32m~/agb-venv/lib/python3.11/site-packages/ee/data.py:408\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    406\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mexecute(num_retries\u001b[38;5;241m=\u001b[39mnum_retries)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 408\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "\u001b[0;31mEEException\u001b[0m: Computation timed out."
     ]
    }
   ],
   "source": [
    "# Pipeline to generate AGB map based on random forest algorithm\n",
    "import ee\n",
    "import geemap\n",
    "import folium\n",
    "import time\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)  # Example: increase limit to 2000\n",
    "\n",
    "ee.Initialize(project='test-project-agb')\n",
    "Map = geemap.Map()\n",
    "\n",
    "# Define the region of interest of Amazon basin\n",
    "# amazon_region = ee.Geometry.Polygon([[[-80.0, 10.0],\n",
    "#             [-20.0, 10.0],\n",
    "#             [-20.0, -65.0],                           \n",
    "#             [-80.0, -65.0],\n",
    "#             [-80.0, 10.0]]]) \n",
    "amazon_region = ee.Geometry.Polygon([[[-80.0, 10.0], \n",
    "                                      [-80.0, -20.0], \n",
    "                                      [-40.0, -20.0], \n",
    "                                      [-40.0, 10.0], \n",
    "                                      [-80.0, 10.0]]])\n",
    "\n",
    "amazon_region_gedi = ee.Geometry.Polygon([[[-65.0, 0.0], \n",
    "                                      [-65.0, -10.0], \n",
    "                                      [-55.0, -10.0], \n",
    "                                      [-55.0, 0.0], \n",
    "                                      [-65.0, 0.0]]])\n",
    "\n",
    "# Load the shapefile as an Earth Engine feature collection\n",
    "amazon_border = ee.FeatureCollection(\"projects/test-project-agb/assets/AmazonBasinLimits-master\")\n",
    "\n",
    "# # Print the first feature to verify\n",
    "# print(amazon_region.first().getInfo())\n",
    "\n",
    "print(\"START\")\n",
    "# load sentinel-1 data \n",
    "spring = ee.Filter.date('2023-01-01', '2023-04-20');\n",
    "lateSpring = ee.Filter.date('2023-04-21', '2023-06-10');\n",
    "summer = ee.Filter.date('2023-06-11', '2023-12-31');\n",
    "\n",
    "# Define the bitmasks\n",
    "cloud_bit_mask = ee.Number(1 << 5)  # Cloud bit is in the 6th bit position\n",
    "cirrus_bit_mask = ee.Number(1 << 9)  # Cirrus bit is in the 10th bit position\n",
    "\n",
    "# # Define a masking function\n",
    "# def mask_edges(image):\n",
    "#     edge = image.lt(-30.0)  # Define an edge mask where values are less than -30\n",
    "#     masked_image = image.mask().And(edge.Not())  # Mask out edges\n",
    "#     return image.updateMask(masked_image)  # Apply the mask\n",
    "    \n",
    "sentinel1 = ee.ImageCollection('COPERNICUS/S1_GRD')\\\n",
    "            .filterBounds(amazon_region)\\\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\\\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
    "            .filter(ee.Filter.eq('instrumentMode', 'IW'))\\\n",
    "            .filter(ee.Filter.inList('orbitProperties_pass', ['ASCENDING', 'DESCENDING']))\n",
    "\n",
    "# Function to apply radiometric calibration\n",
    "def calibrate(image):\n",
    "    gamma_nought = image.multiply(ee.Image.constant(10).pow(image.divide(10)))\n",
    "    return gamma_nought.rename(['VV', 'VH', 'angle'])\n",
    "\n",
    "# Function to remove thermal noise\n",
    "def remove_noise(image):\n",
    "    # Mask low backscatter values\n",
    "    mask = image.gt(-30)  # Keep values above -30 dB\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "# Function to normalize for incidence angle\n",
    "def normalize_angle(image):\n",
    "    angle = image.select('angle')\n",
    "    vv = image.select('VV').subtract(angle.multiply(0.1))  # Adjust VV by incidence angle\n",
    "    vh = image.select('VH').subtract(angle.multiply(0.1))  # Adjust VH similarly\n",
    "    return image.addBands([vv.rename('VV_normalized'), vh.rename('VH_normalized')], overwrite=True)\n",
    "\n",
    "# Optional: Apply speckle filtering\n",
    "def speckle_filter(image):\n",
    "    kernel = ee.Kernel.gaussian(radius=3, sigma=1.5, units='pixels')\n",
    "    vv_filtered = image.select('VV').convolve(kernel).rename('VV_filtered')\n",
    "    vh_filtered = image.select('VH').convolve(kernel).rename('VH_filtered')\n",
    "    return image.addBands([vv_filtered, vh_filtered], overwrite=True)\n",
    "\n",
    "# Apply the processing steps\n",
    "processed_collection = sentinel1.map(calibrate) \n",
    "processed_collection1 = processed_collection.map(remove_noise) \n",
    "processed_collection2 = processed_collection1.map(normalize_angle) \n",
    "processed_collection3 = processed_collection2.map(speckle_filter) \n",
    "\n",
    "\n",
    "# # Composite the processed collection (e.g., median composite)\n",
    "# composite = processed_collection3.median()\n",
    "\n",
    "# Define a function to mask edges\n",
    "def mask_edges(image):\n",
    "    edge_mask = image.mask().reduce(ee.Reducer.min())  # Keep pixels with valid masks\n",
    "    return image.updateMask(edge_mask)\n",
    "    \n",
    "# Select the VV and VH bands\n",
    "sentinel1_vv = processed_collection3.select('VV')\n",
    "sentinel1_vh = processed_collection3.select('VH')\n",
    "\n",
    "# Apply the masking function to each image in the collection\n",
    "sentinel1_vv_masked = sentinel1_vv.map(mask_edges)\n",
    "sentinel1_vv_composite = ee.Image.cat(\n",
    "        sentinel1_vv_masked.filter(spring).mean(),\n",
    "        sentinel1_vv_masked.filter(lateSpring).mean(),\n",
    "        sentinel1_vv_masked.filter(summer).mean());\n",
    "\n",
    "# Apply the masking function to each image in the collection\n",
    "sentinel1_vh_masked = sentinel1_vh.map(mask_edges)\n",
    "sentinel1_vh_composite = ee.Image.cat(\n",
    "        sentinel1_vh_masked.filter(spring).mean(),\n",
    "        sentinel1_vh_masked.filter(lateSpring).mean(),\n",
    "        sentinel1_vh_masked.filter(summer).mean());\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Apply masking to Sentinel-1 data\n",
    "# sentinel1_vv_masked = processed_collection3.select('VV').map(mask_edges)\n",
    "# sentinel1_vh_masked = processed_collection3.select('VH').map(mask_edges)\n",
    "\n",
    "# # Create temporal composites to reduce gaps\n",
    "# sentinel1_vv_composite = sentinel1_vv_masked.reduce(ee.Reducer.median())\n",
    "# sentinel1_vh_composite = sentinel1_vh_masked.reduce(ee.Reducer.median())\n",
    "\n",
    "# Identify gap regions (missing pixels)\n",
    "vv_gap_mask = sentinel1_vv_composite.mask().Not()  # Mask where there are gaps\n",
    "vh_gap_mask = sentinel1_vh_composite.mask().Not()\n",
    "\n",
    "# Fill gaps using focal mean (interpolation)\n",
    "vv_filled = sentinel1_vv_composite.focal_mean(radius=5, kernelType='circle', units='pixels')\n",
    "vh_filled = sentinel1_vh_composite.focal_mean(radius=5, kernelType='circle', units='pixels')\n",
    "\n",
    "# Combine original data with interpolated values to fill gaps\n",
    "final_vv = sentinel1_vv_composite.unmask(vv_filled)\n",
    "final_vh = sentinel1_vh_composite.unmask(vh_filled)\n",
    "\n",
    "# Merge VV and VH bands into a single multi-band image\n",
    "sentinel1_final_filled = final_vv.addBands(final_vh)\n",
    "\n",
    "# load sentinel-2 data \n",
    "sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "                .filterBounds(amazon_region) \\\n",
    "                .filterDate('2023-01-01', '2023-12-31') \\\n",
    "                .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n",
    "\n",
    "# Apply the mask using bitwise AND to check that both cloud and cirrus bits are 0\n",
    "def mask_clouds(image):\n",
    "    qa = image.select('QA60')  # Select the QA60 band that holds cloud and cirrus bit information\n",
    "    mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(qa.bitwiseAnd(cirrus_bit_mask).eq(0))\n",
    "    return image.updateMask(mask)\n",
    "    \n",
    "sentinel2 = sentinel2.map(mask_clouds)\n",
    "\n",
    "# Calculate NDVI\n",
    "ndvi = sentinel2.map(lambda image: image.normalizedDifference(['B8', 'B4']).rename('NDVI')).median()\n",
    "# Calculate EVI\n",
    "def calculate_evi(image):\n",
    "    return image.expression(\n",
    "        '2.5 * ((B8 - B4) / (B8 + 6 * B4 - 7.5 * B2 + 1))',\n",
    "        {\n",
    "            'B8': image.select('B8'),\n",
    "            'B4': image.select('B4'),\n",
    "            'B2': image.select('B2')\n",
    "        }).rename('EVI')\n",
    "\n",
    "evi = sentinel2.map(calculate_evi).median()\n",
    "\n",
    "# Load Landsat 8 Surface Reflectance data\n",
    "landsat8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
    "              .filterBounds(amazon_region) \\\n",
    "              .filterDate('2023-01-01', '2023-12-31') \\\n",
    "              .filter(ee.Filter.lt('CLOUD_COVER', 30))\n",
    "# Calculate NDVI for Landsat 8\n",
    "landsat_ndvi = landsat8.map(lambda image: image.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI')).median()\n",
    "\n",
    "# Load the GLO-30 DEM data from the COPERNICUS collection\n",
    "dem = ee.ImageCollection('COPERNICUS/DEM/GLO30') \\\n",
    "          .filterBounds(amazon_region) \\\n",
    "          .mosaic()\n",
    "\n",
    "# Calculate slope in degrees\n",
    "slope = ee.Terrain.slope(dem)\n",
    "# Calculate aspect in degrees\n",
    "aspect = ee.Terrain.aspect(dem)\n",
    "\n",
    "# # Load the JRC Global Surface Water dataset\n",
    "# water_dataset = ee.Image('JRC/GSW1_4/GlobalSurfaceWater')\n",
    "\n",
    "# # Use the \"occurrence\" band to represent water presence (values > 50 indicate permanent water presence)\n",
    "# river_band = water_dataset.select('occurrence').gt(50).rename('water_presence')\n",
    "\n",
    "# # Load the HydroSHEDS river network dataset\n",
    "# # Replace 'WWF/HydroSHEDS/v1/FreeFlowingRivers' with a specific dataset if needed\n",
    "# river_dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/FreeFlowingRivers')\n",
    "\n",
    "# # Filter the dataset to the Amazon region\n",
    "# amazon_rivers = river_dataset.filterBounds(amazon_region)\n",
    "\n",
    "# # Create a raster layer from the river features\n",
    "# # This creates a binary mask where rivers are 1 and other areas are 0\n",
    "# river_raster = amazon_rivers.reduceToImage(properties=[], reducer=ee.Reducer.constant(1)).unmask(0).rename('river_presence')\n",
    "\n",
    "\n",
    "# Stack all features (Sentinel-1, Sentinel-2, Landsat, DEM) and add river_band as an additional feature\n",
    "feature_stack = sentinel1_final_filled.addBands(ndvi) \\\n",
    "                                  .addBands(evi) \\\n",
    "                                  .addBands(landsat_ndvi) \\\n",
    "                                  .addBands(dem) \\\n",
    "                                  .addBands(slope) \\\n",
    "                                  .addBands(aspect) \n",
    "  # .addBands(river_band)  # Add water presence as a band\n",
    "\n",
    "# print(\"type of feature_stack\", type(feature_stack))\n",
    "\n",
    "# Load GEDI Level 4A data\n",
    "# Read table IDs from a text file\n",
    "with open('table_ids.txt', 'r') as file:\n",
    "    table_ids = [line.strip() for line in file if line.strip()]  # Remove whitespace and empty lines\n",
    "\n",
    "# # Get the list of table_id values\n",
    "# table_ids = gedi_all.aggregate_array('table_id').getInfo()\n",
    "\n",
    "print(\"lenght of table id\", len(table_ids))\n",
    "\n",
    "# Initialize an empty FeatureCollection\n",
    "gedi = ee.FeatureCollection([])\n",
    "\n",
    "i=0\n",
    "# Loop through each table ID and merge them\n",
    "for table_id in table_ids:\n",
    "    print(f\"Processing table ID: {table_id}\")\n",
    "    table = ee.FeatureCollection(table_id).filterBounds(amazon_region_gedi);\n",
    "    gedi = gedi.merge(table)\n",
    "# print('Number of GEDI points:', gedi.size().getInfo())\n",
    "    \n",
    "# Filter invalid AGBD measurements based on 'l4_quality_flag'\n",
    "gedi = gedi.filter(ee.Filter.eq('l4_quality_flag', 1))\n",
    "# print('Number of first filtered GEDI points:', gedi.size().getInfo())\n",
    "\n",
    "# Filter to keep only points with non-null 'agbd' values\n",
    "gedi = gedi.filter(ee.Filter.notNull(['agbd']))\n",
    "# print('Number of filtered GEDI points:', gedi.size().getInfo())\n",
    "\n",
    "# Filter to keep only points with non-null 'agbd' values\n",
    "gedi = gedi.filter(ee.Filter.notNull(['agbd_se']))\n",
    "\n",
    "# # Remove unreliable measurements with a relative standard error > 50%\n",
    "# gedi = gedi.filter(\n",
    "#     ee.Filter.lt(ee.Number(gedi.get('agbd_se')).divide(gedi.get('agbd')).multiply(100), 30)\n",
    "# )\n",
    "\n",
    "# print('Number of filtered GEDI points:', gedi.size().getInfo())\n",
    "\n",
    "# # Convert agbd to integer for smileGradientTreeBoost\n",
    "gedi = gedi.map(lambda feature: feature.set('agbd', ee.Number(feature.get('agbd')).toInt()))\n",
    "\n",
    "# Sample the remote sensing data at GEDI footprint locations\n",
    "training_data = feature_stack.sampleRegions(\n",
    "        collection=gedi,\n",
    "        properties=['agbd'],\n",
    "        scale=100,\n",
    "        tileScale=16,\n",
    "        geometries=True\n",
    ")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "training_set = training_data.randomColumn().filter(ee.Filter.lt('random', 0.8))\n",
    "testing_set = training_data.randomColumn().filter(ee.Filter.gte('random', 0.8))\n",
    "\n",
    "# print('Number of training_data at scale 100m resolution :', training_set.getInfo())\n",
    "\n",
    "\n",
    "# Build a Random Forest model\n",
    "classifier = ee.Classifier.smileRandomForest(100).setOutputMode('REGRESSION')\n",
    "\n",
    "print('Training the model')\n",
    "# Train the model\n",
    "trained_model = classifier.train(\n",
    "    features=training_set,\n",
    "    classProperty='agbd',\n",
    "    inputProperties=feature_stack.bandNames()\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "testing_classified = testing_set.classify(trained_model)\n",
    "error_matrix = testing_classified.errorMatrix('agbd', 'classification')\n",
    "\n",
    "# Print the RMSE and accuracy (optional)\n",
    "print('Error Matrix:', type(error_matrix))\n",
    "\n",
    "\n",
    "# Apply the trained model to predict AGB\n",
    "prediction = feature_stack.classify(trained_model)\n",
    "prediction = prediction.clip(amazon_border)\n",
    "# print(\"Type of agb_prediction\", type(prediction))\n",
    "agb_prediction = ee.ImageCollection(prediction)\n",
    "print(type(agb_prediction))\n",
    "print(\"Finish1\")\n",
    "# Reduce the ImageCollection to a single image (e.g., median)\n",
    "agb_prediction_image = agb_prediction.median()\n",
    "print(type(agb_prediction))\n",
    "print(\"Finish2\")\n",
    "\n",
    "# # Visualization parameters\n",
    "# visualization_params = {\n",
    "#     'min': 0, \n",
    "#     'max': 300, \n",
    "#     'palette': ['#808080' , '5F9EA0', '004080', 'yellow', '7CFC00','5F8575', '228B22','008000', '355E3B', '4F7942']}\n",
    "\n",
    "# # Save as a PNG file\n",
    "# url = agb_prediction_image.getThumbURL(visualization_params)\n",
    "# print(\"Download PNG from this URL:\", url)\n",
    "# # # Set the scale parameter to 10 meters for higher-resolution sampling\n",
    "# # # agb_prediction = ee.ImageCollection(feature_stack.classify(trained_model).reproject(crs='EPSG:4326', scale=100))\n",
    "\n",
    "# Assuming `agb_prediction` is an ee.Image and `region` is an ee.Geometry\n",
    "task = ee.batch.Export.image.toCloudStorage(\n",
    "    image=agb_prediction_image,\n",
    "    description='agb_prediction_image',\n",
    "    bucket='test-agb-bucket',  # Replace with your Google Cloud Storage bucket name\n",
    "    fileNamePrefix='agb_prediction_image',  # Prefix for the exported file\n",
    "    region=amazon_region,  # Convert region to a list of coordinates\n",
    "    scale=100,  # Spatial resolution in meters\n",
    "    fileFormat='GEO_TIFF'  # Export format\n",
    ")\n",
    "# # Configure the export task\n",
    "# task = ee.batch.Export.table.toCloudStorage(\n",
    "#     collection=feature_collection,\n",
    "#     description='ExportFeatureCollection',\n",
    "#     bucket='your-gcs-bucket-name',\n",
    "#     fileNamePrefix='exported_feature_collection',\n",
    "#     fileFormat='CSV'  # Options: 'CSV', 'GeoJSON', 'KML', 'KMZ'\n",
    "# )\n",
    "\n",
    "\n",
    "# # Start the task\n",
    "# task.start()\n",
    "# status = task.status()\n",
    "# print(status)\n",
    "# print(\"Export started\")\n",
    "# # Function to check task status periodically\n",
    "# def check_task_status(task):\n",
    "#     while True:\n",
    "#         status = task.status()\n",
    "#         state = status['state']\n",
    "#         print('Current task state:', state)\n",
    "        \n",
    "#         if state == 'COMPLETED':\n",
    "#             print(\"Export task completed successfully.\")\n",
    "#             break\n",
    "#         elif state == 'FAILED':\n",
    "#             print(\"Export task failed:\", status)\n",
    "#             break\n",
    "        \n",
    "#         # Wait before checking the status again\n",
    "#         time.sleep(30)\n",
    "\n",
    "# # Start monitoring the task\n",
    "# check_task_status(task)\n",
    "\n",
    "\n",
    "Map.addLayer(sentinel1_final_filled, \n",
    "  {'min': -25, 'max': 5},  \n",
    "  'sentinel1_final_filled'\n",
    ");\n",
    "\n",
    "# Map.addLayer(composite, \n",
    "#   {'min': -25, 'max': 5},  \n",
    "#   'composite'\n",
    "# );\n",
    "\n",
    "Map.addLayer(sentinel2, \n",
    "  {'min': -25, 'max': 5}, \n",
    "  'sentinel2'\n",
    ");\n",
    "# Map.addLayer(ndvi, \n",
    "#   {'min': -25, 'max': 5}, \n",
    "#   'ndvi'\n",
    "# );\n",
    "# Map.addLayer(evi, \n",
    "#   {'min': -25, 'max': 5}, \n",
    "#   'evi'\n",
    "# );\n",
    "# Map.addLayer(landsat_ndvi, \n",
    "#   {'min': -25, 'max': 5}, \n",
    "#   'landsat_ndvi'\n",
    "# );\n",
    "# Map.addLayer(dem, \n",
    "#   {'min': -25, 'max': 5}, \n",
    "#   'dem'\n",
    "# );\n",
    "# Map.addLayer(slope, \n",
    "#   {'min': -25, 'max': 5}, \n",
    "#   'slope'\n",
    "# );\n",
    "# Map.addLayer(aspect, \n",
    "#   {'min': -25, 'max': 5}, \n",
    "#   'aspect'\n",
    "# );\n",
    "# Map.addLayer(feature_stack, \n",
    "#   {'min': -25, 'max': 5}, \n",
    "#   'feature_stack'\n",
    "# );\n",
    "# Map.addLayer(gedi, \n",
    "#   {'min': -25, 'max': 5}, \n",
    "#   'gedi'\n",
    "# );\n",
    "# Map.addLayer(training_data, \n",
    "#   {'min': -25, 'max': 5}, \n",
    "#   'training_data'\n",
    "# );\n",
    "Map.addLayer(amazon_region_gedi, \n",
    "  {}, \n",
    "  'amazon_region_gedi'\n",
    ");\n",
    "Map.addLayer(amazon_border, {}, 'amazon_border');\n",
    "# Map.addLayer(agb_prediction, \n",
    "#   {'min': 0, 'max': 300, 'palette': ['006400' , '228B22', '7CFC00', '5F8575', '5F9EA0','4F7942', '228B22','355E3B', '004080']}, \n",
    "#   'agb_prediction'\n",
    "# );\n",
    "Map.centerObject(amazon_region, 6)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6aaa3c-6f88-49fe-9a91-751a539d19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower resolution by increasing scale (e.g., from 30 to 100 or more)\n",
    "output_file = \"agb_prediction_low_res.tif\"\n",
    "\n",
    "geemap.ee_export_image(\n",
    "    agb_prediction_image,\n",
    "    filename=output_file,\n",
    "    scale=1000,  # Lower resolution (e.g., 500 meters)\n",
    "    region=amazon_region,\n",
    "    file_per_band=False  # Single file export\n",
    ")\n",
    "\n",
    "print(f\"Image saved locally as {output_file} with lower resolution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654fe7ed-8594-415e-bb51-0295e630c02b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "ee.Initialize()\n",
    "\n",
    "# Define your Area of Interest (AOI) and date range\n",
    "\n",
    "aoi = ee.Geometry.Polygon([[[-85.0, 10.0], \n",
    "                                      [-85.0, -20.0], \n",
    "                                      [-20.0, -20.0], \n",
    "                                      [-20.0, 10.0], \n",
    "                                      [-85.0, 10.0]]])\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "# Load Sentinel-1 data\n",
    "s1_collection = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(start_date, end_date) \\\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "    .filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')) \\\n",
    "    .filter(ee.Filter.eq('resolution_meters', 10)) \\\n",
    "    .select(['VV', 'VH', 'angle'])\n",
    "\n",
    "s1_collection = ee.ImageCollection('COPERNICUS/S1_GRD')\\\n",
    "            .filterBounds(amazon_region)\\\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\\\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
    "            .filter(ee.Filter.eq('instrumentMode', 'IW'))\\\n",
    "            .filter(ee.Filter.inList('orbitProperties_pass', ['ASCENDING', 'DESCENDING']))\n",
    "\n",
    "# Function to apply radiometric calibration\n",
    "def calibrate(image):\n",
    "    gamma_nought = image.multiply(ee.Image.constant(10).pow(image.divide(10)))\n",
    "    return gamma_nought.rename(['VV', 'VH', 'angle'])\n",
    "\n",
    "# Function to remove thermal noise\n",
    "def remove_noise(image):\n",
    "    # Mask low backscatter values\n",
    "    mask = image.gt(-30)  # Keep values above -30 dB\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "# Function to normalize for incidence angle\n",
    "def normalize_angle(image):\n",
    "    angle = image.select('angle')\n",
    "    vv = image.select('VV').subtract(angle.multiply(0.1))  # Adjust VV by incidence angle\n",
    "    vh = image.select('VH').subtract(angle.multiply(0.1))  # Adjust VH similarly\n",
    "    return image.addBands([vv.rename('VV_normalized'), vh.rename('VH_normalized')], overwrite=True)\n",
    "\n",
    "# Optional: Apply speckle filtering\n",
    "def speckle_filter(image):\n",
    "    kernel = ee.Kernel.gaussian(radius=30, sigma=1.5, units='pixels')\n",
    "    vv_filtered = image.select('VV').convolve(kernel).rename('VV_filtered')\n",
    "    vh_filtered = image.select('VH').convolve(kernel).rename('VH_filtered')\n",
    "    return image.addBands([vv_filtered, vh_filtered], overwrite=True)\n",
    "\n",
    "# Apply the processing steps\n",
    "processed_collection = s1_collection.map(calibrate) \n",
    "processed_collection1 = processed_collection.map(remove_noise) \n",
    "processed_collection2 = processed_collection1.map(normalize_angle) \n",
    "processed_collection3 = processed_collection2.map(speckle_filter) \n",
    "\n",
    "\n",
    "# Composite the processed collection (e.g., median composite)\n",
    "composite = processed_collection3.median()\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(amazon_border, {}, 'amazon_border');\n",
    "\n",
    "Map.addLayer(s1_collection, \n",
    "  {'min': -25, 'max': 0, 'bands': ['VV']},\n",
    "   'sentinel1'\n",
    ");\n",
    "Map.addLayer(processed_collection, \n",
    "  {'min': -25, 'max': 0, 'bands': ['VV']},\n",
    "   'processed_collection'\n",
    ");\n",
    "Map.addLayer(processed_collection1, \n",
    "  {'min': -25, 'max': 0, 'bands': ['VV']},\n",
    "   'processed_collection1'\n",
    ");\n",
    "Map.addLayer(processed_collection2, \n",
    "  {'min': -25, 'max': 0, 'bands': ['VV']},\n",
    "   'processed_collection2'\n",
    ");\n",
    "Map.addLayer(processed_collection3, \n",
    "  {'min': -25, 'max': 0, 'bands': ['VV']},\n",
    "   'processed_collection3'\n",
    ");\n",
    "Map.addLayer(composite, \n",
    "  {'min': -25, 'max': 0, 'bands': ['VV']},\n",
    "   'composite'\n",
    ");\n",
    "\n",
    "Map.centerObject(amazon_region, 6)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f3d505-386a-469c-9a21-c08dd8631d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(sentinel1_final_filled, \n",
    "  {'min': -25, 'max': 5},  \n",
    "  'sentinel1_final_filled'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd1e5a-7efe-4001-ac0d-721420e96c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
