{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78db2208-0638-4921-87de-20048690506b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[-64.38047870088286, -20.202095534083398], [-64.37960473704723, -20.20884665933983], [-64.37538192638276, -20.21042958088765], [-64.37538192638276, -20.202095528644666], [-64.38047870088286, -20.202095534083398]]]}, 'id': '00000000000000000000', 'properties': {'Id': 0, 'area': 0.46}}\n",
      "START\n",
      "type of feature_stack <class 'ee.image.Image'>\n",
      "lenght of table id 439\n",
      "JJ\n",
      "{'state': 'READY', 'description': 'Export_training_data_to_CloudStorage', 'priority': 100, 'creation_timestamp_ms': 1733477495928, 'update_timestamp_ms': 1733477495928, 'start_timestamp_ms': 0, 'task_type': 'EXPORT_FEATURES', 'id': 'I3MBPOPRZIAV7NYHFZILN3MI', 'name': 'projects/test-project-agb/operations/I3MBPOPRZIAV7NYHFZILN3MI'}\n",
      "Export started\n",
      "Current task state: READY\n",
      "Current task state: READY\n",
      "Current task state: READY\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 236\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExport started\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Start monitoring the task\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m \u001b[43mcheck_task_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 219\u001b[0m, in \u001b[0;36mcheck_task_status\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Wait before checking the status again\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Pipeline to generate AGB map based on random forest algorithm\n",
    "import ee\n",
    "import geemap\n",
    "import folium\n",
    "import time\n",
    "\n",
    "ee.Initialize()\n",
    "Map = geemap.Map()\n",
    "\n",
    "# Define the region of interest of Amazon basin\n",
    "# amazon_region = ee.Geometry.Polygon([[[-80.0, 10.0],\n",
    "#             [-20.0, 10.0],\n",
    "#             [-20.0, -65.0],                           \n",
    "#             [-80.0, -65.0],\n",
    "#             [-80.0, 10.0]]]) \n",
    "amazon_region = ee.Geometry.Polygon([[[-77.0, 5.0], \n",
    "                                      [-77.0, -17.0], \n",
    "                                      [-48.0, -17.0], \n",
    "                                      [-48.0, 5.0], \n",
    "                                      [-77.0, 5.0]]])\n",
    "\n",
    "# Load the shapefile as an Earth Engine feature collection\n",
    "amazon_region = ee.FeatureCollection(\"projects/test-project-agb/assets/AmazonBasinLimits-master\")\n",
    "\n",
    "# Print the first feature to verify\n",
    "print(amazon_region.first().getInfo())\n",
    "\n",
    "print(\"START\")\n",
    "# load sentinel-1 data \n",
    "spring = ee.Filter.date('2022-03-01', '2022-04-20');\n",
    "lateSpring = ee.Filter.date('2022-04-21', '2022-06-10');\n",
    "summer = ee.Filter.date('2022-06-11', '2022-08-31');\n",
    "\n",
    "# Define the bitmasks\n",
    "cloud_bit_mask = ee.Number(1 << 5)  # Cloud bit is in the 6th bit position\n",
    "cirrus_bit_mask = ee.Number(1 << 9)  # Cirrus bit is in the 10th bit position\n",
    "\n",
    "# Define a masking function\n",
    "def mask_edges(image):\n",
    "    edge = image.lt(-30.0)  # Define an edge mask where values are less than -30\n",
    "    masked_image = image.mask().And(edge.Not())  # Mask out edges\n",
    "    return image.updateMask(masked_image)  # Apply the mask\n",
    "    \n",
    "sentinel1 = ee.ImageCollection('COPERNICUS/S1_GRD')\\\n",
    "            .filterBounds(amazon_region)\\\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\\\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
    "            .filter(ee.Filter.eq('instrumentMode', 'IW'))\\\n",
    "            .filter(ee.Filter.inList('orbitProperties_pass', ['ASCENDING', 'DESCENDING']))\n",
    "\n",
    "# Select the VV and VH bands\n",
    "sentinel1_vv = sentinel1.select('VV')\n",
    "sentinel1_vh = sentinel1.select('VH')\n",
    "\n",
    "# Apply the masking function to each image in the collection\n",
    "sentinel1_vv_masked = sentinel1_vv.map(mask_edges)\n",
    "sentinel1_vv_final = ee.Image.cat(\n",
    "        sentinel1_vv_masked.filter(spring).mean(),\n",
    "        sentinel1_vv_masked.filter(lateSpring).mean(),\n",
    "        sentinel1_vv_masked.filter(summer).mean());\n",
    "\n",
    "# Apply the masking function to each image in the collection\n",
    "sentinel1_vh_masked = sentinel1_vh.map(mask_edges)\n",
    "sentinel1_vh_final = ee.Image.cat(\n",
    "        sentinel1_vh_masked.filter(spring).mean(),\n",
    "        sentinel1_vh_masked.filter(lateSpring).mean(),\n",
    "        sentinel1_vh_masked.filter(summer).mean());\n",
    "\n",
    "# load sentinel-2 data \n",
    "sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "                .filterBounds(amazon_region) \\\n",
    "                .filterDate('2022-01-01', '2022-12-31') \\\n",
    "                .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n",
    "\n",
    "# Apply the mask using bitwise AND to check that both cloud and cirrus bits are 0\n",
    "def mask_clouds(image):\n",
    "    qa = image.select('QA60')  # Select the QA60 band that holds cloud and cirrus bit information\n",
    "    mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(qa.bitwiseAnd(cirrus_bit_mask).eq(0))\n",
    "    return image.updateMask(mask)\n",
    "    \n",
    "sentinel2 = sentinel2.map(mask_clouds)\n",
    "\n",
    "# Calculate NDVI\n",
    "ndvi = sentinel2.map(lambda image: image.normalizedDifference(['B8', 'B4']).rename('NDVI')).median()\n",
    "# Calculate EVI\n",
    "def calculate_evi(image):\n",
    "    return image.expression(\n",
    "        '2.5 * ((B8 - B4) / (B8 + 6 * B4 - 7.5 * B2 + 1))',\n",
    "        {\n",
    "            'B8': image.select('B8'),\n",
    "            'B4': image.select('B4'),\n",
    "            'B2': image.select('B2')\n",
    "        }).rename('EVI')\n",
    "\n",
    "evi = sentinel2.map(calculate_evi).median()\n",
    "\n",
    "# Load Landsat 8 Surface Reflectance data\n",
    "landsat8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
    "              .filterBounds(amazon_region) \\\n",
    "              .filterDate('2022-01-01', '2022-12-31') \\\n",
    "              .filter(ee.Filter.lt('CLOUD_COVER', 50))\n",
    "# Calculate NDVI for Landsat 8\n",
    "landsat_ndvi = landsat8.map(lambda image: image.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI')).median()\n",
    "\n",
    "# Load the GLO-30 DEM data from the COPERNICUS collection\n",
    "dem = ee.ImageCollection('COPERNICUS/DEM/GLO30') \\\n",
    "          .filterBounds(amazon_region) \\\n",
    "          .mosaic()\n",
    "\n",
    "# Calculate slope in degrees\n",
    "slope = ee.Terrain.slope(dem)\n",
    "# Calculate aspect in degrees\n",
    "aspect = ee.Terrain.aspect(dem)\n",
    "\n",
    "# # Load the JRC Global Surface Water dataset\n",
    "# water_dataset = ee.Image('JRC/GSW1_4/GlobalSurfaceWater')\n",
    "\n",
    "# # Use the \"occurrence\" band to represent water presence (values > 50 indicate permanent water presence)\n",
    "# river_band = water_dataset.select('occurrence').gt(50).rename('water_presence')\n",
    "\n",
    "# # Load the HydroSHEDS river network dataset\n",
    "# # Replace 'WWF/HydroSHEDS/v1/FreeFlowingRivers' with a specific dataset if needed\n",
    "# river_dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/FreeFlowingRivers')\n",
    "\n",
    "# # Filter the dataset to the Amazon region\n",
    "# amazon_rivers = river_dataset.filterBounds(amazon_region)\n",
    "\n",
    "# # Create a raster layer from the river features\n",
    "# # This creates a binary mask where rivers are 1 and other areas are 0\n",
    "# river_raster = amazon_rivers.reduceToImage(properties=[], reducer=ee.Reducer.constant(1)).unmask(0).rename('river_presence')\n",
    "\n",
    "\n",
    "# Stack all features (Sentinel-1, Sentinel-2, Landsat, DEM) and add river_band as an additional feature\n",
    "feature_stack = sentinel1_vh_final.addBands(sentinel1_vv_final) \\\n",
    "                                  .addBands(ndvi) \\\n",
    "                                  .addBands(evi) \\\n",
    "                                  .addBands(landsat_ndvi) \\\n",
    "                                  .addBands(dem) \\\n",
    "                                  .addBands(slope) \\\n",
    "                                  .addBands(aspect) \n",
    "  # .addBands(river_band)  # Add water presence as a band\n",
    "\n",
    "print(\"type of feature_stack\", type(feature_stack))\n",
    "\n",
    "# Load GEDI Level 4A data\n",
    "gedi_all = ee.FeatureCollection('LARSE/GEDI/GEDI04_A_002_INDEX')\\\n",
    "        .filter('time_start > \"2022-01-01\" && time_end < \"2022-03-30\"')\\\n",
    "        .filterBounds(amazon_region);\n",
    "\n",
    "# Get the list of table_id values\n",
    "table_ids = gedi_all.aggregate_array('table_id').getInfo()\n",
    "\n",
    "print(\"lenght of table id\", len(table_ids))\n",
    "\n",
    "# Initialize an empty FeatureCollection\n",
    "gedi = ee.FeatureCollection([])\n",
    "\n",
    "i=0\n",
    "# Loop through each table ID and merge them\n",
    "for table_id in table_ids:\n",
    "    # Load each table and merge\n",
    "    table = ee.FeatureCollection(table_id).filterBounds(amazon_region);\n",
    "    gedi = gedi.merge(table)\n",
    "\n",
    "# Filter invalid AGBD measurements based on 'l4_quality_flag'\n",
    "gedi = gedi.filter(ee.Filter.eq('l4_quality_flag', 1))\n",
    "# print('Number of 1st filtered GEDI points:', gedi.size().getInfo())  \n",
    "\n",
    "# Filter to keep only points with non-null 'agbd' values\n",
    "gedi = gedi.filter(ee.Filter.notNull(['agbd_se']))\n",
    "\n",
    "# Remove unreliable measurements with a relative standard error > 50%\n",
    "# gedi = gedi.filter(\n",
    "#     ee.Filter.lt(ee.Number(gedi.get('agbd_se')).divide(gedi.get('agbd')).multiply(100), 10)\n",
    "# )\n",
    "print(\"JJ\")\n",
    "# print('Number of 2nd filtered GEDI points:', gedi.size().getInfo()) \n",
    "\n",
    "# Filter to keep only points with non-null 'agbd' values\n",
    "gedi = gedi.filter(ee.Filter.notNull(['agbd']))\n",
    "# print('Number of 3rd filtered GEDI points:', gedi.size().getInfo())\n",
    "\n",
    "# Convert agbd to integer for smileGradientTreeBoost\n",
    "gedi = gedi.map(lambda feature: feature.set('agbd', ee.Number(feature.get('agbd')).toInt()))\n",
    "\n",
    "# Sample the remote sensing data at GEDI footprint locations\n",
    "training_data = feature_stack.sampleRegions(\n",
    "        collection=gedi,\n",
    "        properties=['agbd'],\n",
    "        scale=100,\n",
    "        tileScale=16,\n",
    "        geometries=True\n",
    ")\n",
    "# task = ee.batch.Export.image.toCloudStorage(\n",
    "#         image=training_data,         # Pass image directly, not in a dictionary\n",
    "#         description='AGB_Prediction_GCS',  # Task description\n",
    "#         bucket='test-agb-bucket',    # GCS bucket name\n",
    "#         fileNamePrefix='agb_training_data',  # Prefix for the file name in the bucket\n",
    "#         scale=100,                    # Scale in meters\n",
    "#         maxPixels=1e8,               # Max number of pixels\n",
    "#         fileFormat='GeoTIFF'          # File format\n",
    "# )\n",
    "\n",
    "# Function to check task status periodically\n",
    "def check_task_status(task):\n",
    "    while True:\n",
    "        status = task.status()\n",
    "        state = status['state']\n",
    "        print('Current task state:', state)\n",
    "        \n",
    "        if state == 'COMPLETED':\n",
    "            print(\"Export task completed successfully.\")\n",
    "            break\n",
    "        elif state == 'FAILED':\n",
    "            print(\"Export task failed:\", status)\n",
    "            break\n",
    "        \n",
    "        # Wait before checking the status again\n",
    "        time.sleep(30)\n",
    "        \n",
    "# Export the FeatureCollection to Google Drive\n",
    "task = ee.batch.Export.table.toCloudStorage(\n",
    "    collection=training_data,\n",
    "    description='Export_training_data_to_CloudStorage',\n",
    "    bucket='test-agb-bucket',  # Replace with your GCS bucket name\n",
    "    fileNamePrefix='agb_training_data',  # Replace with desired file path and prefix\n",
    "    fileFormat='CSV'  # Format can be 'CSV', 'GeoJSON', etc.\n",
    ")\n",
    "\n",
    "# Start the export task\n",
    "task.start()\n",
    "status = task.status()\n",
    "print(status)\n",
    "print(\"Export started\")\n",
    "# Start monitoring the task\n",
    "check_task_status(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e52e741-8336-4a39-9e82-f995dcc9ed59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca4618f-bd2e-4ffc-b728-ed9869721cca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
