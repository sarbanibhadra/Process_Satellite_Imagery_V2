{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9e0f9-e35d-4ce3-8a54-3168ab038d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Initialize Google Earth Engine\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "\n",
    "# Define the Amazon Basin polygon (example placeholder)\n",
    "amazon_basin = ee.Geometry.Polygon([\n",
    "    [\n",
    "        [-80, -10], [-80, 5], [-65, 5], [-65, -10], [-80, -10]\n",
    "    ]\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "def load_datasets():\n",
    "    sentinel1 = ee.ImageCollection(\"COPERNICUS/S1_GRD\").filterBounds(amazon_basin)\n",
    "    sentinel2 = ee.ImageCollection(\"COPERNICUS/S2\").filterBounds(amazon_basin)\n",
    "    landsat = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\").filterBounds(amazon_basin)\n",
    "    dem = ee.Image(\"USGS/SRTMGL1_003\")\n",
    "    gedi = ee.FeatureCollection(\"LARSE/GEDI/GEDI04_A_002\").filterBounds(amazon_basin)\n",
    "    \n",
    "    return sentinel1, sentinel2, landsat, dem, gedi\n",
    "\n",
    "# Preprocess Sentinel-1 (reduce mean)\n",
    "def preprocess_sentinel1(sentinel1):\n",
    "    return sentinel1.select(['VV', 'VH']).mean()\n",
    "\n",
    "# Preprocess Sentinel-2 (cloud masking and mean reduction)\n",
    "def preprocess_sentinel2(sentinel2):\n",
    "    def mask_clouds(image):\n",
    "        qa = image.select('QA60')\n",
    "        cloud_mask = qa.bitwiseAnd(1 << 10).eq(0).And(qa.bitwiseAnd(1 << 11).eq(0))\n",
    "        return image.updateMask(cloud_mask)\n",
    "    sentinel2 = sentinel2.map(mask_clouds)\n",
    "    return sentinel2.select(['B2', 'B3', 'B4', 'B8']).mean()\n",
    "\n",
    "# Preprocess Landsat 8 (cloud masking and mean reduction)\n",
    "def preprocess_landsat(landsat):\n",
    "    def mask_clouds(image):\n",
    "        qa = image.select('QA_PIXEL')\n",
    "        cloud_mask = qa.bitwiseAnd(1 << 5).eq(0).And(qa.bitwiseAnd(1 << 7).eq(0))\n",
    "        return image.updateMask(cloud_mask)\n",
    "    landsat = landsat.map(mask_clouds)\n",
    "    return landsat.select(['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5']).mean()\n",
    "\n",
    "# Combine all datasets into a single image\n",
    "def create_composite(sentinel1, sentinel2, landsat, dem):\n",
    "    sentinel1 = preprocess_sentinel1(sentinel1)\n",
    "    sentinel2 = preprocess_sentinel2(sentinel2)\n",
    "    landsat = preprocess_landsat(landsat)\n",
    "    composite = sentinel1.addBands(sentinel2).addBands(landsat).addBands(dem)\n",
    "    return composite\n",
    "\n",
    "# Extract training data from GEDI\n",
    "def extract_training_data(gedi, composite):\n",
    "    samples = composite.sampleRegions(\n",
    "        collection=gedi,\n",
    "        properties=['agbd'],  # Assume GEDI AGBD field is 'agbd'\n",
    "        scale=30\n",
    "    )\n",
    "    return samples\n",
    "\n",
    "# Batch process samples to avoid memory issues\n",
    "def batch_samples_to_xarray(samples, batch_size=1000):\n",
    "    features = []\n",
    "    for i in range(0, len(samples['features']), batch_size):\n",
    "        batch = samples['features'][i:i+batch_size]\n",
    "        df = pd.DataFrame(batch)\n",
    "        properties = df['properties'].apply(pd.Series)\n",
    "        features.append(properties)\n",
    "    return xr.Dataset.from_dataframe(pd.concat(features, ignore_index=True))\n",
    "\n",
    "# Train AGB Prediction Model\n",
    "def train_model(features, target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    print(f\"Model MSE: {mse}\")\n",
    "    return model\n",
    "\n",
    "# Main Execution\n",
    "sentinel1, sentinel2, landsat, dem, gedi = load_datasets()\n",
    "composite = create_composite(sentinel1, sentinel2, landsat, dem)\n",
    "samples = extract_training_data(gedi, composite).getInfo()\n",
    "data = batch_samples_to_xarray(samples)\n",
    "\n",
    "# Split features and target\n",
    "features = data.drop_vars('agbd').to_array().to_numpy()\n",
    "target = data['agbd'].to_numpy()\n",
    "\n",
    "# Train model\n",
    "model = train_model(features, target)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, \"agb_model.pkl\")\n",
    "\n",
    "print(\"Model training completed and saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
