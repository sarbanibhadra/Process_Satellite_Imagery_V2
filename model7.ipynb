{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ae57c9-bbd4-43d5-b0d5-b4f6fcd7f3c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mda\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mee\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dask'"
     ]
    }
   ],
   "source": [
    "import dask.array as da\n",
    "import h5py\n",
    "import ee\n",
    "import geemap\n",
    "from google.cloud import storage\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize Google Earth Engine\n",
    "ee.Initialize()\n",
    "\n",
    "# Function to fetch and filter HDF5 LiDAR data from GCS\n",
    "def fetch_and_filter_lidar_from_gcs(bucket_name, filter_flags):\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blobs = list(bucket.list_blobs(prefix=\"\"))\n",
    "    lidar_files = [blob.name for blob in blobs if blob.name.endswith('.h5')]\n",
    "\n",
    "    filtered_data = []\n",
    "\n",
    "    for lidar_file in lidar_files:\n",
    "        local_file = f\"/tmp/{lidar_file.split('/')[-1]}\"\n",
    "        blob = bucket.blob(lidar_file)\n",
    "        blob.download_to_filename(local_file)\n",
    "\n",
    "        with h5py.File(local_file, 'r') as f:\n",
    "            agbd = f['agbd'][:]\n",
    "            l4_flag = f['l4_flag'][:]\n",
    "            mask = (l4_flag == filter_flags['l4_flag']) & (~np.isnan(agbd))\n",
    "            filtered_data.append(agbd[mask])\n",
    "\n",
    "    return da.concatenate(filtered_data, axis=0)\n",
    "\n",
    "# Fetch DEM data from GEE\n",
    "def fetch_dem_data(region):\n",
    "    dem = ee.Image(\"USGS/SRTMGL1_003\").clip(region)\n",
    "    return geemap.ee_to_numpy(dem, region=region, default_value=-9999)\n",
    "\n",
    "# Fetch Landsat Data from GEE\n",
    "def fetch_landsat_data(region, start_date, end_date):\n",
    "    landsat = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_TOA\")\\\n",
    "        .filterBounds(region)\\\n",
    "        .filterDate(start_date, end_date)\\\n",
    "        .select(['B2', 'B3', 'B4', 'B5', 'B6', 'B7'])\n",
    "    composite = landsat.median().clip(region)\n",
    "    return geemap.ee_to_numpy(composite, region=region, default_value=-9999)\n",
    "\n",
    "# Fetch Sentinel-1 Data for Seasonal Timeframes\n",
    "def fetch_sentinel_data_seasons(region):\n",
    "    seasons = {\n",
    "        'spring': ('2021-03-01', '2021-05-31'),\n",
    "        'late_spring': ('2021-06-01', '2021-06-30'),\n",
    "        'summer': ('2021-07-01', '2021-09-30')\n",
    "    }\n",
    "\n",
    "    seasonal_data = {}\n",
    "\n",
    "    for season, (start_date, end_date) in seasons.items():\n",
    "        s1 = ee.ImageCollection(\"COPERNICUS/S1_GRD\")\\\n",
    "            .filterBounds(region)\\\n",
    "            .filterDate(start_date, end_date)\\\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\\\n",
    "            .select('VV')\n",
    "        composite = s1.median().clip(region)\n",
    "        seasonal_data[season] = geemap.ee_to_numpy(composite, region=region, default_value=-9999)\n",
    "\n",
    "    return seasonal_data\n",
    "\n",
    "# Preprocess and combine features\n",
    "def preprocess_data(lidar, dem, landsat, sentinel_seasons):\n",
    "    lidar_array = da.from_array(lidar, chunks=(1000, 1000))\n",
    "    dem_array = da.from_array(dem, chunks=(1000, 1000))\n",
    "    landsat_array = da.from_array(landsat, chunks=(1000, 1000, landsat.shape[-1]))\n",
    "\n",
    "    sentinel_arrays = [da.from_array(sentinel_seasons[season], chunks=(1000, 1000)) for season in sentinel_seasons]\n",
    "    sentinel_combined = da.concatenate(sentinel_arrays, axis=-1)\n",
    "\n",
    "    combined_features = da.concatenate([lidar_array, dem_array, landsat_array, sentinel_combined], axis=-1)\n",
    "    return combined_features\n",
    "\n",
    "# Predict AGB and Calculate RMSE\n",
    "def predict_agb(features, model, true_agb):\n",
    "    features = features.compute()  # Convert Dask array to NumPy for prediction\n",
    "    agb_pred = model.predict(features.reshape(-1, features.shape[-1]))\n",
    "    agb_pred = agb_pred.reshape(features.shape[:-1])\n",
    "\n",
    "    if true_agb is not None:\n",
    "        true_agb = true_agb.compute()  # Convert Dask array to NumPy\n",
    "        rmse = np.sqrt(mean_squared_error(true_agb.flatten(), agb_pred.flatten()))\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "\n",
    "    return agb_pred\n",
    "\n",
    "# Save AGB Map to HDF5\n",
    "def save_agb_map(agb_map, output_file):\n",
    "    with h5py.File(output_file, 'w') as f:\n",
    "        f.create_dataset('agb', data=agb_map)\n",
    "\n",
    "# Main Workflow\n",
    "def main():\n",
    "    bucket_name = 'test-agb-bucket/GEDIL4A2023'\n",
    "    output_file = '/tmp/agb_map.h5'\n",
    "\n",
    "    # Define filter flags for LiDAR data\n",
    "    filter_flags = {\n",
    "        'l4_flag': 1,  # Flag to filter by L4\n",
    "        'agbd_min': 0  # Minimum AGBD threshold\n",
    "    }\n",
    "\n",
    "    # # Define region of interest (ROI)\n",
    "    # region = ee.Geometry.Polygon([\n",
    "    #     [[-60, -10], [-60, 0], [-50, 0], [-50, -10], [-60, -10]]\n",
    "    # ])\n",
    "    # Load the shapefile as an Earth Engine feature collection\n",
    "    region = ee.FeatureCollection(\"projects/test-project-agb/assets/AmazonBasinLimits-master\")\n",
    "\n",
    "\n",
    "    # Fetch and filter LiDAR data\n",
    "    print(\"Fetching and filtering LiDAR data...\")\n",
    "    lidar = fetch_and_filter_lidar_from_gcs(bucket_name, filter_flags)\n",
    "\n",
    "    print(\"Fetching DEM data...\")\n",
    "    dem = fetch_dem_data(region)\n",
    "\n",
    "    print(\"Fetching Landsat data...\")\n",
    "    landsat = fetch_landsat_data(region, '2021-01-01', '2021-12-31')\n",
    "\n",
    "    print(\"Fetching Sentinel-1 data for seasons...\")\n",
    "    sentinel_seasons = fetch_sentinel_data_seasons(region)\n",
    "\n",
    "    print(\"Preprocessing data...\")\n",
    "    features = preprocess_data(lidar, dem, landsat, sentinel_seasons)\n",
    "\n",
    "    # Load pre-trained model\n",
    "    print(\"Loading model...\")\n",
    "    # model = joblib.load('agb_model.pkl')\n",
    "\n",
    "    # # Assuming true AGB values are available for RMSE calculation\n",
    "    # true_agb = lidar  # Replace with actual true AGB values if different\n",
    "\n",
    "    # # Predict AGB\n",
    "    # print(\"Predicting AGB map...\")\n",
    "    # agb_map = predict_agb(features, model, true_agb)\n",
    "\n",
    "    # # Save AGB map\n",
    "    # print(f\"Saving AGB map to {output_file}...\")\n",
    "    # save_agb_map(agb_map, output_file)\n",
    "\n",
    "    print(\"AGB prediction complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550c5b6-d8a7-47bd-a2db-7a569833a692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
